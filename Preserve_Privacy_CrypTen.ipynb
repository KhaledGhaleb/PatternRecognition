{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preserve Privacy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAqnG/R3zKNaMTBoVN+tI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhaledGhaleb/PatternRecognition/blob/main/Preserve_Privacy_CrypTen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-yevArUFyvn",
        "outputId": "e53b1fd3-2a19-445d-a115-f1ffded1d1e3"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/CrypTen.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CrypTen'...\n",
            "remote: Enumerating objects: 4285, done.\u001b[K\n",
            "remote: Counting objects: 100% (487/487), done.\u001b[K\n",
            "remote: Compressing objects: 100% (169/169), done.\u001b[K\n",
            "remote: Total 4285 (delta 335), reused 445 (delta 317), pack-reused 3798\u001b[K\n",
            "Receiving objects: 100% (4285/4285), 14.61 MiB | 31.70 MiB/s, done.\n",
            "Resolving deltas: 100% (3037/3037), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-4tXZxXF7y8"
      },
      "source": [
        "%cd /content/CrypTen\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py build \n",
        "!python setup.py install \n",
        "\n",
        "!pip install -r requirements.examples.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUufaoo1yE97",
        "outputId": "3f537d4a-0aa5-4dce-c3ab-816aa0709d48"
      },
      "source": [
        "%cd /content/CrypTen\n",
        "import torch\n",
        "import crypten\n",
        "\n",
        "crypten.init()\n",
        "\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "x_enc = crypten.cryptensor(x) # encrypt\n",
        "\n",
        "x_dec = x_enc.get_plain_text() # decrypt\n",
        "\n",
        "y_enc = crypten.cryptensor([2.0, 3.0, 4.0])\n",
        "sum_xy = x_enc + y_enc # add encrypted tensors\n",
        "sum_xy_dec = sum_xy.get_plain_text() # decrypt sum\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CrypTen\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/CrypTen/crypten/__init__.py:59: RuntimeWarning: CrypTen is already initialized.\n",
            "  warnings.warn(\"CrypTen is already initialized.\", RuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19nDHg6kycAA",
        "outputId": "c3f4efad-bf2b-4bd1-bf2a-25163e8ccab1"
      },
      "source": [
        "crypten.__version__\n",
        "crypten.__all__\n",
        "#crypten.r (x_dec,x_enc,sum_xy_dec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CrypTensor',\n",
              " 'no_grad',\n",
              " 'enable_grad',\n",
              " 'set_grad_enabled',\n",
              " 'debug',\n",
              " 'generators',\n",
              " 'init',\n",
              " 'init_thread',\n",
              " 'log',\n",
              " 'mpc',\n",
              " 'nn',\n",
              " 'print',\n",
              " 'uninit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRJwt1VgKoz1"
      },
      "source": [
        "## Operations on Encrypted Tensors\n",
        "Now let's look at what we can do with our ```CrypTensors```.\n",
        "\n",
        "#### Arithmetic Operations\n",
        "We can carry out regular arithmetic operations between ```CrypTensors```, as well as between ```CrypTensors``` and plaintext tensors. Note that these operations never reveal any information about encrypted tensors (internally or externally) and return an encrypted tensor output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv6wEO0vKoz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea2bf707-b928-4355-d89c-94f6c52af390"
      },
      "source": [
        "#Arithmetic operations between CrypTensors and plaintext tensors\n",
        "x_enc = crypten.cryptensor([1.0, 2.0, 3.0])\n",
        "\n",
        "y = 2.0\n",
        "y_enc = crypten.cryptensor(2.0)\n",
        "\n",
        "\n",
        "# Addition\n",
        "z_enc1 = x_enc + y      # Public\n",
        "z_enc2 = x_enc + y_enc  # Private\n",
        "crypten.print(\"\\nPublic  addition:\", z_enc1.get_plain_text())\n",
        "crypten.print(\"Private addition:\", z_enc2.get_plain_text())\n",
        "\n",
        "\n",
        "# Subtraction\n",
        "z_enc1 = x_enc - y      # Public\n",
        "z_enc2 = x_enc - y_enc  # Private\n",
        "crypten.print(\"\\nPublic  subtraction:\", z_enc1.get_plain_text())\n",
        "print(\"Private subtraction:\", z_enc2.get_plain_text())\n",
        "\n",
        "# Multiplication\n",
        "z_enc1 = x_enc * y      # Public\n",
        "z_enc2 = x_enc * y_enc  # Private\n",
        "print(\"\\nPublic  multiplication:\", z_enc1.get_plain_text())\n",
        "print(\"Private multiplication:\", z_enc2.get_plain_text())\n",
        "\n",
        "# Division\n",
        "z_enc1 = x_enc / y      # Public\n",
        "z_enc2 = x_enc / y_enc  # Private\n",
        "print(\"\\nPublic  division:\", z_enc1.get_plain_text())\n",
        "print(\"Private division:\", z_enc2.get_plain_text())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Public  addition: tensor([3., 4., 5.])\n",
            "Private addition: tensor([3., 4., 5.])\n",
            "\n",
            "Public  subtraction: tensor([-1.,  0.,  1.])\n",
            "Private subtraction: tensor([-1.,  0.,  1.])\n",
            "\n",
            "Public  multiplication: tensor([2., 4., 6.])\n",
            "Private multiplication: tensor([2., 4., 6.])\n",
            "\n",
            "Public  division: tensor([0.5000, 1.0000, 1.5000])\n",
            "Private division: tensor([0.5000, 1.0000, 1.5000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Grhy-6Km7I"
      },
      "source": [
        "### Arithmetic secret-sharing\n",
        "Let's look more closely at the `crypten.mpc.arithmetic` <i>ptype</i>. Most of the mathematical operations implemented by `CrypTensors` are implemented using arithmetic secret sharing. As such, `crypten.mpc.arithmetic` is the default <i>ptype</i> for newly generated `CrypTensors`. \n",
        "\n",
        "Let's begin by creating a new `CrypTensor` using `ptype=crypten.mpc.arithmetic` to enforce that the encryption is done via arithmetic secret sharing. We can print values of each share to confirm that values are being encrypted properly. \n",
        "\n",
        "To do so, we will need to create multiple parties to hold each share. We do this here using the `@mpc.run_multiprocess` function decorator, which we developed to execute crypten code from a single script (as we have in a Jupyter notebook). CrypTen follows the standard MPI programming model: it runs a separate process for each party, but each process runs an identical (complete) program. Each process has a `rank` variable to identify itself.\n",
        "\n",
        "Note that the sum of the two `_tensor` attributes below is equal to a scaled representation of the input. (Because MPC requires values to be integers, we scale input floats to a fixed-point encoding before encryption.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ON-PLusKm7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cda63a2-a5e4-4bb3-cfba-8e838fd5c48c"
      },
      "source": [
        "import crypten.mpc as mpc\n",
        "import crypten.communicator as comm \n",
        "\n",
        "@mpc.run_multiprocess(world_size=5)\n",
        "def examine_arithmetic_shares():\n",
        "    x_enc = crypten.cryptensor([1, 2, 3], ptype=crypten.mpc.arithmetic)\n",
        "    \n",
        "    rank = comm.get().get_rank()\n",
        "    crypten.print(f\"\\nRank {rank}:\\n {x_enc}\\n\", in_order=True)\n",
        "    crypten.print(f\"\\nDec {rank}:\\n {x_enc.get_plain_text()}\\n\", in_order=True)\n",
        "        \n",
        "x = examine_arithmetic_shares()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Rank 0:\n",
            " MPCTensor(\n",
            "\t_tensor=tensor([-3598738080953073994,  9003552085897807922,  -279861436019269901])\n",
            "\tplain_text=HIDDEN\n",
            "\tptype=ptype.arithmetic\n",
            ")\n",
            "\n",
            "\n",
            "Rank 1:\n",
            " MPCTensor(\n",
            "\t_tensor=tensor([ 7833974411593636444, -2694371945925532942,  5176061646185038739])\n",
            "\tplain_text=HIDDEN\n",
            "\tptype=ptype.arithmetic\n",
            ")\n",
            "\n",
            "\n",
            "Rank 2:\n",
            " MPCTensor(\n",
            "\t_tensor=tensor([-2976069281557984283, -9082648626149359093, -6551171292853620349])\n",
            "\tplain_text=HIDDEN\n",
            "\tptype=ptype.arithmetic\n",
            ")\n",
            "\n",
            "\n",
            "Rank 3:\n",
            " MPCTensor(\n",
            "\t_tensor=tensor([ 3953936127357642696,  8680992562830967484, -5084847915176496700])\n",
            "\tplain_text=HIDDEN\n",
            "\tptype=ptype.arithmetic\n",
            ")\n",
            "\n",
            "\n",
            "Rank 4:\n",
            " MPCTensor(\n",
            "\t_tensor=tensor([-5213103176440155327, -5907524076653752299,  6739818997864544819])\n",
            "\tplain_text=HIDDEN\n",
            "\tptype=ptype.arithmetic\n",
            ")\n",
            "\n",
            "\n",
            "Dec 0:\n",
            " tensor([1., 2., 3.])\n",
            "\n",
            "\n",
            "Dec 1:\n",
            " tensor([1., 2., 3.])\n",
            "\n",
            "\n",
            "Dec 2:\n",
            " tensor([1., 2., 3.])\n",
            "\n",
            "\n",
            "Dec 3:\n",
            " tensor([1., 2., 3.])\n",
            "\n",
            "\n",
            "Dec 4:\n",
            " tensor([1., 2., 3.])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjZIWFHaKo0N"
      },
      "source": [
        "#### Advanced mathematics\n",
        "We are also able to compute more advanced mathematical functions on ```CrypTensors``` using iterative approximations. CrypTen provides MPC support for functions like reciprocal, exponential, logarithm, square root, tanh, etc. Notice that these are subject to numerical error due to the approximations used. \n",
        "\n",
        "Additionally, note that some of these functions will fail silently when input values are outside of the range of convergence for the approximations used. These do not produce errors because value are encrypted and cannot be checked without decryption. Exercise caution when using these functions. (It is good practice here to normalize input values for certain models.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOIU3_F-Ko0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db42e9c9-006c-4163-ab7e-5c0df597bf42"
      },
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "#Construct example input CrypTensor\n",
        "x = torch.tensor([0.1, 0.3, 0.5, 1.0, 1.5, 2.0, 2.5])\n",
        "x_enc = crypten.cryptensor(x)\n",
        "\n",
        "# Reciprocal\n",
        "z = x.reciprocal()          # Public\n",
        "z_enc = x_enc.reciprocal()  # Private\n",
        "print(\"\\nPublic  reciprocal:\", z)\n",
        "print(\"Private reciprocal:\", z_enc.get_plain_text())\n",
        "\n",
        "# Logarithm\n",
        "z = x.log()          # Public\n",
        "z_enc = x_enc.log()  # Private\n",
        "print(\"\\nPublic  logarithm:\", z)\n",
        "print(\"Private logarithm:\", z_enc.get_plain_text())\n",
        "\n",
        "# Exp\n",
        "z = x.exp()          # Public\n",
        "z_enc = x_enc.exp()  # Private\n",
        "print(\"\\nPublic  exponential:\", z)\n",
        "print(\"Private exponential:\", z_enc.get_plain_text())\n",
        "\n",
        "# Sqrt\n",
        "z = x.sqrt()          # Public\n",
        "z_enc = x_enc.sqrt()  # Private\n",
        "print(\"\\nPublic  square root:\", z)\n",
        "print(\"Private square root:\", z_enc.get_plain_text())\n",
        "\n",
        "# Tanh\n",
        "z = x.tanh()          # Public\n",
        "z_enc = x_enc.tanh()  # Private\n",
        "print(\"\\nPublic  tanh:\", z)\n",
        "print(\"Private tanh:\", z_enc.get_plain_text())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Public  reciprocal: tensor([10.0000,  3.3333,  2.0000,  1.0000,  0.6667,  0.5000,  0.4000])\n",
            "Private reciprocal: tensor([10.0009,  3.3335,  2.0000,  1.0000,  0.6667,  0.5000,  0.4000])\n",
            "\n",
            "Public  logarithm: tensor([-2.3026, -1.2040, -0.6931,  0.0000,  0.4055,  0.6931,  0.9163])\n",
            "Private logarithm: tensor([    -2.3181,     -1.2110,     -0.6997,      0.0004,      0.4038,\n",
            "             0.6918,      0.9150])\n",
            "\n",
            "Public  exponential: tensor([ 1.1052,  1.3499,  1.6487,  2.7183,  4.4817,  7.3891, 12.1825])\n",
            "Private exponential: tensor([ 1.1021,  1.3440,  1.6468,  2.7121,  4.4574,  7.3280, 12.0188])\n",
            "\n",
            "Public  square root: tensor([0.3162, 0.5477, 0.7071, 1.0000, 1.2247, 1.4142, 1.5811])\n",
            "Private square root: tensor([0.3147, 0.5477, 0.7071, 0.9989, 1.2237, 1.4141, 1.5811])\n",
            "\n",
            "Public  tanh: tensor([0.0997, 0.2913, 0.4621, 0.7616, 0.9051, 0.9640, 0.9866])\n",
            "Private tanh: tensor([0.0994, 0.2914, 0.4636, 0.7636, 0.9069, 0.9652, 0.9873])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKlAQ08JKm7b"
      },
      "source": [
        "## Data Sources\n",
        "CrypTen follows the standard MPI programming model: it runs a separate process for each party, but each process runs an identical (complete) program. Each process has a `rank` variable to identify itself.\n",
        "\n",
        "If the process with rank `i` is the source of data `x`, then `x` gets encrypted with `i` as its source value (denoted as `src`). However, MPI protocols require that both processes to provide a tensor with the same size as their input. CrypTen ignores all data provided from non-source processes when encrypting.\n",
        "\n",
        "In the next example, we'll show how to use the `rank` and `src` values to encrypt tensors. Here, we will have each of 3 parties generate a value `x` which is equal to its own `rank` value. Within the loop, 3 encrypted tensors are created, each with a different source. When these tensors are decrypted, we can verify that the tensors are generated using the tensor provided by the source process.\n",
        "\n",
        "(Note that `crypten.cryptensor` uses rank 0 as the default source if none is provided.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KQTzvnXKm7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a41c10-02a1-4f7f-8c11-451851a40d68"
      },
      "source": [
        "@mpc.run_multiprocess(world_size=3)\n",
        "def examine_sources():\n",
        "    # Create a different tensor on each rank\n",
        "    rank = comm.get().get_rank()\n",
        "    x = torch.tensor(rank)\n",
        "    crypten.print(f\"Rank {rank}: {x}\", in_order=True)\n",
        "\n",
        "    world_size = comm.get().get_world_size()\n",
        "    for i in range(world_size):\n",
        "        x_enc = crypten.cryptensor(x, src=i)\n",
        "        z = x_enc.get_plain_text()\n",
        "        \n",
        "        # Only print from one process to avoid duplicates\n",
        "        crypten.print(f\"Rank {rank} Source {i}: {z}\", in_order=False)\n",
        "        #print(f\"Print(Gobal) Rank {rank} Source {i}: {z}\")\n",
        "\n",
        "        \n",
        "x = examine_sources()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rank 0: 0\n",
            "Rank 1: 1\n",
            "Rank 2: 2\n",
            "Rank 0 Source 0: 0.0\n",
            "Rank 0 Source 1: 1.0\n",
            "Rank 0 Source 2: 2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "gIZudUXtKnHn"
      },
      "source": [
        "# Introduction to Access Control\n",
        "\n",
        "We can now start using CrypTen to carry out private computations in some common use cases. In this tutorial, we will demonstrate how CrypTen would apply for the scenarios described in the Introduction. In all scenarios, we'll use a simple two-party setting and demonstrate how we can learn a linear SVM. In the process, we will see how access control works in CrypTen.\n",
        "\n",
        "As usual, we'll begin by importing the `crypten` and `torch` libraries, and initialize `crypten` with `crypten.init()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnEsRpSLKnH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4953e9-5898-4a0e-bf6a-1ee80597f225"
      },
      "source": [
        "import crypten\n",
        "import torch\n",
        "\n",
        "crypten.init()\n",
        "torch.set_num_threads(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/crypten-0.1.0-py3.7.egg/crypten/__init__.py:59: RuntimeWarning: CrypTen is already initialized.\n",
            "  warnings.warn(\"CrypTen is already initialized.\", RuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtSvcPMOKnIm"
      },
      "source": [
        "### Setup\n",
        "In this tutorial, we will train a Linear SVM to perform binary classification. We will first generate 1000 ground truth samples using 100 features and a randomly generated hyperplane to separate positive and negative examples. \n",
        "\n",
        "(Note: this will cause our classes to be linearly separable, so a linear SVM will be able to classify with perfect accuracy given the right parameters.)\n",
        "\n",
        "We will also include a test set of examples (that are also linearly separable by the same hyperplane) to show that the model learns a general hyperplane rather than memorizing the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--yDKb0dKnJ5"
      },
      "source": [
        "num_features = 100\n",
        "num_train_examples = 1000\n",
        "num_test_examples = 100\n",
        "epochs = 40\n",
        "lr = 3.0\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(1)\n",
        "\n",
        "features = torch.randn(num_features, num_train_examples)\n",
        "w_true = torch.randn(1, num_features)\n",
        "b_true = torch.randn(1)\n",
        "\n",
        "labels = w_true.matmul(features).add(b_true).sign()\n",
        "\n",
        "test_features = torch.randn(num_features, num_test_examples)\n",
        "test_labels = w_true.matmul(test_features).add(b_true).sign()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK85WGcFKnKA"
      },
      "source": [
        "Now that we have generated our dataset, we will train our SVM in four different access control scenarios across two parties, Alice and Bob:\n",
        "\n",
        "- Data Labeling: Alice has access to features, while Bob has access to labels\n",
        "- Feature Aggregation: Alice has access to the first 50 features, while Bob has access to the last 50 features\n",
        "- Data Augmentation: Alice has access to the first 500 examples, while Bob has access to the last 500 examples\n",
        "- Model Hiding: Alice has access to `w_true` and `b_true`, while Bob has access to data samples to be classified\n",
        "\n",
        "Throughout this tutorial, we will assume Alice is using the rank 0 process, while Bob is using the rank 1 process. Additionally we will initialize our weights using random values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cUj5AGAKnKD"
      },
      "source": [
        "ALICE = 0\n",
        "BOB = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHiE2gnFKnKE"
      },
      "source": [
        "In each example, we will use the same code to train our linear SVM once the features and labels are properly encrypted. This code is contained in `examples/mpc_linear_svm`, but it is unnecessary to understand the training code to properly use access control. The training process itself is discussed in depth in later tutorials.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-QPnlaqKnKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f0f02d-c0e4-4b75-8446-850278945ab6"
      },
      "source": [
        "%cd /content/CrypTen\n",
        "%pwd\n",
        "#from CrypTen.examples.mpc_linear_svm\n",
        "from examples.mpc_linear_svm.mpc_linear_svm import train_linear_svm, evaluate_linear_svm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CrypTen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHs2ABn4KnKJ"
      },
      "source": [
        "## Saving / Loading Data\n",
        "\n",
        "We have now generated features and labels for our model to learn. In the scenarios we explore in this tutorial, we would like to ensure that each party only has access to some subset of the data we have generated. To do so, we will use special save / load methods that CrypTen provides to handle loading only to a specified party and synchronizing across processes. \n",
        "\n",
        "We will use `crypten.save_from_party()` here to save data from a particular source, then we will load using `crypten.load_from_party()` in each example to load on a particular source. The following code will save all data we will use to files, then each example will load its data as necessary.\n",
        "\n",
        "(Note that because we are operating on a single machine, all processes will have access to all of the files we are using. However, this still will work as expected when operating across machines.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyP9N1lHKnKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a80f65-95a7-4a9f-a8b5-23addbb9cb8b"
      },
      "source": [
        "from crypten import mpc\n",
        "\n",
        "# Specify file locations to save each piece of data\n",
        "filenames = {\n",
        "    \"features\": \"/tmp/features.pth\",\n",
        "    \"labels\": \"/tmp/labels.pth\",\n",
        "    \"features_alice\": \"/tmp/features_alice.pth\",\n",
        "    \"features_bob\": \"/tmp/features_bob.pth\",\n",
        "    \"samples_alice\": \"/tmp/samples_alice.pth\",\n",
        "    \"samples_bob\": \"/tmp/samples_bob.pth\",\n",
        "    \"w_true\": \"/tmp/w_true.pth\",\n",
        "    \"b_true\": \"/tmp/b_true.pth\",\n",
        "    \"test_features\": \"/tmp/test_features.pth\",\n",
        "    \"test_labels\": \"/tmp/test_labels.pth\",\n",
        "}\n",
        "\n",
        "\n",
        "@mpc.run_multiprocess(world_size=2)\n",
        "def save_all_data():\n",
        "    # Save features, labels for Data Labeling example\n",
        "    crypten.save(features, filenames[\"features\"])\n",
        "    crypten.save(labels, filenames[\"labels\"])\n",
        "    \n",
        "    # Save split features for Feature Aggregation example\n",
        "    features_alice = features[:50]\n",
        "    features_bob = features[50:]\n",
        "    \n",
        "    crypten.save_from_party(features_alice, filenames[\"features_alice\"], src=ALICE)\n",
        "    crypten.save_from_party(features_bob, filenames[\"features_bob\"], src=BOB)\n",
        "    \n",
        "    # Save split dataset for Dataset Aggregation example\n",
        "    samples_alice = features[:, :500]\n",
        "    samples_bob = features[:, 500:]\n",
        "    crypten.save_from_party(samples_alice, filenames[\"samples_alice\"], src=ALICE)\n",
        "    crypten.save_from_party(samples_bob, filenames[\"samples_bob\"], src=BOB)\n",
        "    \n",
        "    # Save true model weights and biases for Model Hiding example\n",
        "    crypten.save_from_party(w_true, filenames[\"w_true\"], src=ALICE)\n",
        "    crypten.save_from_party(b_true, filenames[\"b_true\"], src=ALICE)\n",
        "    \n",
        "    crypten.save_from_party(test_features, filenames[\"test_features\"], src=BOB)\n",
        "    crypten.save_from_party(test_labels, filenames[\"test_labels\"], src=BOB)\n",
        "    \n",
        "save_all_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB-hcB1OKnKc"
      },
      "source": [
        "## Scenario 1: Data Labeling\n",
        "\n",
        "Our first example will focus on the <i>Data Labeling</i> scenario. In this example, Alice has access to features, while Bob has access to the labels. We will train our linear svm by encrypting the features from Alice and the labels from Bob, then training our SVM using an aggregation of the encrypted data.\n",
        "\n",
        "In order to indicate the source of a given encrypted tensor, we encrypt our tensor using `crypten.load()` (from a file) or `crypten.cryptensor()` (from a tensor) using a keyword argument `src`. This `src` argument takes the rank of the party we want to encrypt from (recall that ALICE is 0 and BOB is 1). \n",
        "\n",
        "(If the `src` is not specified, it will default to the rank 0 party. We will use the default when encrypting public values since the source is irrelevant in this case.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6sNm7IyKnKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e1b242-7860-4ebd-80d7-dd4d49df44e2"
      },
      "source": [
        "from crypten import mpc\n",
        "\n",
        "@mpc.run_multiprocess(world_size=2)\n",
        "def data_labeling_example():\n",
        "    \"\"\"Apply data labeling access control model\"\"\"\n",
        "    # Alice loads features, Bob loads labels\n",
        "    features_enc = crypten.load_from_party(filenames[\"features\"], src=ALICE)\n",
        "    labels_enc = crypten.load_from_party(filenames[\"labels\"], src=BOB)\n",
        "    \n",
        "    # Execute training\n",
        "    w, b = train_linear_svm(features_enc, labels_enc, epochs=epochs, lr=lr)\n",
        "    \n",
        "    # Evaluate model\n",
        "    evaluate_linear_svm(test_features, test_labels, w, b)\n",
        "        \n",
        "data_labeling_example()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 --- Training Accuracy 53.40%\n",
            "Epoch 1 --- Training Accuracy 58.70%\n",
            "Epoch 2 --- Training Accuracy 63.80%\n",
            "Epoch 3 --- Training Accuracy 68.30%\n",
            "Epoch 4 --- Training Accuracy 73.60%\n",
            "Epoch 5 --- Training Accuracy 78.00%\n",
            "Epoch 6 --- Training Accuracy 81.00%\n",
            "Epoch 7 --- Training Accuracy 84.60%\n",
            "Epoch 8 --- Training Accuracy 87.00%\n",
            "Epoch 9 --- Training Accuracy 90.40%\n",
            "Epoch 10 --- Training Accuracy 91.50%\n",
            "Epoch 11 --- Training Accuracy 92.90%\n",
            "Epoch 12 --- Training Accuracy 93.80%\n",
            "Epoch 13 --- Training Accuracy 94.40%\n",
            "Epoch 14 --- Training Accuracy 95.30%\n",
            "Epoch 15 --- Training Accuracy 96.30%\n",
            "Epoch 16 --- Training Accuracy 96.10%\n",
            "Epoch 17 --- Training Accuracy 96.70%\n",
            "Epoch 18 --- Training Accuracy 96.70%\n",
            "Epoch 19 --- Training Accuracy 97.30%\n",
            "Epoch 20 --- Training Accuracy 97.70%\n",
            "Epoch 21 --- Training Accuracy 98.00%\n",
            "Epoch 22 --- Training Accuracy 98.60%\n",
            "Epoch 23 --- Training Accuracy 98.60%\n",
            "Epoch 24 --- Training Accuracy 98.60%\n",
            "Epoch 25 --- Training Accuracy 99.10%\n",
            "Epoch 26 --- Training Accuracy 99.40%\n",
            "Epoch 27 --- Training Accuracy 99.50%\n",
            "Epoch 28 --- Training Accuracy 99.40%\n",
            "Epoch 29 --- Training Accuracy 99.30%\n",
            "Epoch 30 --- Training Accuracy 99.50%\n",
            "Epoch 31 --- Training Accuracy 99.60%\n",
            "Epoch 32 --- Training Accuracy 99.60%\n",
            "Epoch 33 --- Training Accuracy 99.90%\n",
            "Epoch 34 --- Training Accuracy 99.80%\n",
            "Epoch 35 --- Training Accuracy 99.80%\n",
            "Epoch 36 --- Training Accuracy 99.30%\n",
            "Epoch 37 --- Training Accuracy 99.80%\n",
            "Epoch 38 --- Training Accuracy 99.70%\n",
            "Epoch 39 --- Training Accuracy 99.80%\n",
            "Test accuracy 100.00%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0jNpweEKnKe"
      },
      "source": [
        "## Scenario 2: Feature Aggregation\n",
        "\n",
        "Next, we'll show how we can use CrypTen in the <i>Feature Aggregation</i> scenario. Here Alice and Bob each have 50 features for each sample, and would like to use their combined features to train a model. As before, Alice and Bob wish to keep their respective data private. This scenario can occur when multiple parties measure different features of a similar system, and their measurements may be proprietary or otherwise sensitive.\n",
        "\n",
        "Unlike the last scenario, one of our variables is split among two parties. This means we will have to concatenate the tensors encrypted from each party before passing them to the training code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgjxH8IOKnKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c878f4e6-b38e-46bf-8b0a-39280c5a30dd"
      },
      "source": [
        "@mpc.run_multiprocess(world_size=2)\n",
        "def feature_aggregation_example():\n",
        "    \"\"\"Apply feature aggregation access control model\"\"\"\n",
        "    # Alice loads some features, Bob loads other features\n",
        "    features_alice_enc = crypten.load_from_party(filenames[\"features_alice\"], src=ALICE)\n",
        "    features_bob_enc = crypten.load_from_party(filenames[\"features_bob\"], src=BOB)\n",
        "    \n",
        "    # Concatenate features\n",
        "    features_enc = crypten.cat([features_alice_enc, features_bob_enc], dim=0)\n",
        "    \n",
        "    # Encrypt labels\n",
        "    labels_enc = crypten.cryptensor(labels)\n",
        "    \n",
        "    # Execute training\n",
        "    w, b = train_linear_svm(features_enc, labels_enc, epochs=epochs, lr=lr)\n",
        "    \n",
        "    # Evaluate model\n",
        "    evaluate_linear_svm(test_features, test_labels, w, b)\n",
        "        \n",
        "feature_aggregation_example()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 --- Training Accuracy 53.40%\n",
            "Epoch 1 --- Training Accuracy 58.70%\n",
            "Epoch 2 --- Training Accuracy 63.80%\n",
            "Epoch 3 --- Training Accuracy 68.30%\n",
            "Epoch 4 --- Training Accuracy 73.60%\n",
            "Epoch 5 --- Training Accuracy 78.00%\n",
            "Epoch 6 --- Training Accuracy 81.00%\n",
            "Epoch 7 --- Training Accuracy 84.60%\n",
            "Epoch 8 --- Training Accuracy 87.00%\n",
            "Epoch 9 --- Training Accuracy 90.40%\n",
            "Epoch 10 --- Training Accuracy 91.50%\n",
            "Epoch 11 --- Training Accuracy 92.90%\n",
            "Epoch 12 --- Training Accuracy 93.80%\n",
            "Epoch 13 --- Training Accuracy 94.30%\n",
            "Epoch 14 --- Training Accuracy 95.50%\n",
            "Epoch 15 --- Training Accuracy 95.80%\n",
            "Epoch 16 --- Training Accuracy 96.30%\n",
            "Epoch 17 --- Training Accuracy 96.60%\n",
            "Epoch 18 --- Training Accuracy 96.80%\n",
            "Epoch 19 --- Training Accuracy 97.60%\n",
            "Epoch 20 --- Training Accuracy 97.70%\n",
            "Epoch 21 --- Training Accuracy 97.90%\n",
            "Epoch 22 --- Training Accuracy 98.20%\n",
            "Epoch 23 --- Training Accuracy 98.10%\n",
            "Epoch 24 --- Training Accuracy 98.90%\n",
            "Epoch 25 --- Training Accuracy 99.20%\n",
            "Epoch 26 --- Training Accuracy 99.20%\n",
            "Epoch 27 --- Training Accuracy 99.50%\n",
            "Epoch 28 --- Training Accuracy 99.80%\n",
            "Epoch 29 --- Training Accuracy 99.60%\n",
            "Epoch 30 --- Training Accuracy 99.60%\n",
            "Epoch 31 --- Training Accuracy 99.50%\n",
            "Epoch 32 --- Training Accuracy 99.90%\n",
            "Epoch 33 --- Training Accuracy 99.90%\n",
            "Epoch 34 --- Training Accuracy 100.00%\n",
            "Epoch 35 --- Training Accuracy 100.00%\n",
            "Epoch 36 --- Training Accuracy 100.00%\n",
            "Epoch 37 --- Training Accuracy 100.00%\n",
            "Epoch 38 --- Training Accuracy 100.00%\n",
            "Epoch 39 --- Training Accuracy 100.00%\n",
            "Test accuracy 100.00%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KRBIgSmKnKg"
      },
      "source": [
        "## Scenario 3: Dataset Augmentation\n",
        "\n",
        "The next example shows how we can use CrypTen in a <i>Data Augmentation</i> scenario. Here Alice and Bob each have 500 samples, and would like to learn a classifier over their combined sample data. This scenario can occur in applications where several parties may each have access to a small amount of sensitive data, where no individual party has enough data to train an accurate model.\n",
        "\n",
        "Like the last scenario, one of our variables is split amongst parties, so we will have to concatenate tensors from encrypted from different parties. The main difference from the last scenario is that we are concatenating over the other dimension (the sample dimension rather than the feature dimension)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSAIWC9YKnKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfdf199-e88b-4b25-df73-326efa78d4ed"
      },
      "source": [
        "@mpc.run_multiprocess(world_size=2)\n",
        "def dataset_augmentation_example():\n",
        "    \"\"\"Apply dataset augmentation access control model\"\"\" \n",
        "    # Alice loads some samples, Bob loads other samples\n",
        "    samples_alice_enc = crypten.load_from_party(filenames[\"samples_alice\"], src=ALICE)\n",
        "    samples_bob_enc = crypten.load_from_party(filenames[\"samples_bob\"], src=BOB)\n",
        "    \n",
        "    # Concatenate features\n",
        "    samples_enc = crypten.cat([samples_alice_enc, samples_bob_enc], dim=1)\n",
        "    \n",
        "    labels_enc = crypten.cryptensor(labels)\n",
        "    \n",
        "    # Execute training\n",
        "    w, b = train_linear_svm(samples_enc, labels_enc, epochs=epochs, lr=lr)\n",
        "    \n",
        "    # Evaluate model\n",
        "    evaluate_linear_svm(test_features, test_labels, w, b)\n",
        "        \n",
        "dataset_augmentation_example()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 --- Training Accuracy 53.40%\n",
            "Epoch 1 --- Training Accuracy 58.70%\n",
            "Epoch 2 --- Training Accuracy 63.80%\n",
            "Epoch 3 --- Training Accuracy 68.30%\n",
            "Epoch 4 --- Training Accuracy 73.60%\n",
            "Epoch 5 --- Training Accuracy 78.00%\n",
            "Epoch 6 --- Training Accuracy 81.00%\n",
            "Epoch 7 --- Training Accuracy 84.60%\n",
            "Epoch 8 --- Training Accuracy 87.00%\n",
            "Epoch 9 --- Training Accuracy 90.40%\n",
            "Epoch 10 --- Training Accuracy 91.50%\n",
            "Epoch 11 --- Training Accuracy 92.90%\n",
            "Epoch 12 --- Training Accuracy 93.80%\n",
            "Epoch 13 --- Training Accuracy 94.30%\n",
            "Epoch 14 --- Training Accuracy 95.50%\n",
            "Epoch 15 --- Training Accuracy 95.80%\n",
            "Epoch 16 --- Training Accuracy 96.30%\n",
            "Epoch 17 --- Training Accuracy 96.60%\n",
            "Epoch 18 --- Training Accuracy 96.80%\n",
            "Epoch 19 --- Training Accuracy 97.60%\n",
            "Epoch 20 --- Training Accuracy 97.70%\n",
            "Epoch 21 --- Training Accuracy 97.90%\n",
            "Epoch 22 --- Training Accuracy 98.20%\n",
            "Epoch 23 --- Training Accuracy 98.10%\n",
            "Epoch 24 --- Training Accuracy 98.90%\n",
            "Epoch 25 --- Training Accuracy 99.20%\n",
            "Epoch 26 --- Training Accuracy 99.20%\n",
            "Epoch 27 --- Training Accuracy 99.50%\n",
            "Epoch 28 --- Training Accuracy 99.80%\n",
            "Epoch 29 --- Training Accuracy 99.60%\n",
            "Epoch 30 --- Training Accuracy 99.60%\n",
            "Epoch 31 --- Training Accuracy 99.50%\n",
            "Epoch 32 --- Training Accuracy 99.90%\n",
            "Epoch 33 --- Training Accuracy 99.90%\n",
            "Epoch 34 --- Training Accuracy 100.00%\n",
            "Epoch 35 --- Training Accuracy 100.00%\n",
            "Epoch 36 --- Training Accuracy 100.00%\n",
            "Epoch 37 --- Training Accuracy 100.00%\n",
            "Epoch 38 --- Training Accuracy 100.00%\n",
            "Epoch 39 --- Training Accuracy 100.00%\n",
            "Test accuracy 100.00%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OURROhy1KnKt"
      },
      "source": [
        "## Scenario 4: Model Hiding\n",
        "\n",
        "The last scenario we will explore involves <i>model hiding</i>. Here, Alice has a pre-trained model that cannot be revealed, while Bob would like to use this model to evaluate on private data sample(s). This scenario can occur when a pre-trained model is proprietary or contains sensitive information, but can provide value to other parties with sensitive data.\n",
        "\n",
        "This scenario is somewhat different from the previous examples because we are not interested in training the model. Therefore, we do not need labels. Instead, we will demonstrate this example by encrypting the true model parameters (`w_true` and `b_true`) from Alice and encrypting the test set from Bob for evaluation.\n",
        "\n",
        "(Note: Because we are using the true weights and biases used to generate the test labels, we will get 100% accuracy.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwSAgD_sKnKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455e973e-7c5a-433f-b595-1d1412b3c5df"
      },
      "source": [
        "@mpc.run_multiprocess(world_size=2)\n",
        "def model_hiding_example():\n",
        "    \"\"\"Apply model hiding access control model\"\"\"\n",
        "    # Alice loads the model\n",
        "    w_true_enc = crypten.load_from_party(filenames[\"w_true\"], src=ALICE)\n",
        "    b_true_enc = crypten.load_from_party(filenames[\"b_true\"], src=ALICE)\n",
        "    \n",
        "    # Bob loads the features to be evaluated\n",
        "    test_features_enc = crypten.load_from_party(filenames[\"test_features\"], src=BOB)\n",
        "    \n",
        "    # Evaluate model\n",
        "    evaluate_linear_svm(test_features_enc, test_labels, w_true_enc, b_true_enc)\n",
        "    \n",
        "model_hiding_example()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 100.00%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "yD2VPYtVb5wF"
      },
      "source": [
        "# Classification with Encrypted Neural Networks\n",
        "\n",
        "In this tutorial, we'll look at how we can achieve the <i>Model Hiding</i> application we discussed in the Introduction. That is, suppose say Alice has a trained model she wishes to keep private, and Bob has some data he wishes to classify while keeping it private. We will see how CrypTen allows Alice and Bob to coordinate and classify the data, while achieving their privacy requirements.\n",
        "\n",
        "To simulate this scenario, we will begin with Alice training a simple neural network on MNIST data. Then we'll see how Alice and Bob encrypt their network and data respectively, classify the encrypted data and finally decrypt the labels.\n",
        "\n",
        "## Setup\n",
        "\n",
        "We first import the `torch` and `crypten` libraries, and initialize `crypten`. We will use a helper script `mnist_utils.py` to split the public MNIST data into Alice's portion and Bob's portion. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntNSfX5Wb5wO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe3dc9c-199d-4879-f4df-aa7af4bc836d"
      },
      "source": [
        "import crypten\n",
        "import torch\n",
        "\n",
        "crypten.init()\n",
        "torch.set_num_threads(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CrypTen/crypten/__init__.py:59: RuntimeWarning: CrypTen is already initialized.\n",
            "  warnings.warn(\"CrypTen is already initialized.\", RuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpqeaH2Bb5wR"
      },
      "source": [
        "# Run script that downloads the publicly available MNIST data, and splits the data as required.\n",
        "%run ./tutorials/mnist_utils.py --option train_v_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elIAzzRlb5wT"
      },
      "source": [
        "# Define Alice's network\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AliceNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AliceNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        " \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "    \n",
        "crypten.common.serial.register_safe_class(AliceNet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yjDGvKhb5wV"
      },
      "source": [
        "We will also define a helper routine `compute_accuracy` to make it easy to compute the accuracy of the output we get."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0SBSV_Fb5wW"
      },
      "source": [
        "def compute_accuracy(output, labels):\n",
        "    pred = output.argmax(1)\n",
        "    correct = pred.eq(labels)\n",
        "    correct_count = correct.sum(0, keepdim=True).float()\n",
        "    accuracy = correct_count.mul_(100.0 / output.size(0))\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuPKBMp0b5wY"
      },
      "source": [
        "## Encrypting a Pre-trained Model\n",
        "\n",
        "Assume that Alice has a pre-trained network ready to classify data. Let's see how we can use CrypTen to encrypt this network, so it can be used to classify data without revealing its parameters. We'll use the pre-trained model in `models/tutorial4_alice_model.pth` in this tutorial. As in Tutorial 3, we will assume Alice is using the rank 0 process, while Bob is using the rank 1 process. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwrnA2j4b5wa"
      },
      "source": [
        "ALICE = 0\n",
        "BOB = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WQJel4Mb5wb"
      },
      "source": [
        "In CrypTen, encrypting PyTorch network is straightforward: we load a PyTorch model from file to the appropriate source, convert it to a CrypTen model and then encrypt it. Let us understand each of these steps.\n",
        "\n",
        "As we did with CrypTensors in Tutorial 3, we will use CrypTen's load functionality (i.e., `crypten.load`) to read a model from file to a particular source. The source is indicated by the keyword argument `src`. As in Tutorial 3, this src argument tells us the rank of the party we want to load the model to (and later, encrypt the model from). In addition, here we also need to provide a dummy model to tell CrypTen the model's structure. The dummy model is indicated by the keyword argument `dummy_model`. Note that unlike loading a tensor, the result from `crypten.load` is not encrypted. Instead, only the `src` party's model is populated from the file.\n",
        "\n",
        "Once the model is loaded, we call the function `from_pytorch`: this function sets up a CrypTen network from the PyTorch network. It takes the plaintext network as input as well as dummy input. The dummy input must be a `torch` tensor of the same shape as a potential input to the network, however the values inside the tensor do not matter.  \n",
        "\n",
        "Finally, we call `encrypt` on the CrypTen network to encrypt its parameters. Once we call the `encrypt` function, the models `encrypted` property will verify that the model parameters have been encrypted. (Encrypted CrypTen networks can also be decrypted using the `decrypt` function)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeicCab6b5we",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21739bb-c65e-401b-9acc-23860c55fc2e"
      },
      "source": [
        "# Load pre-trained model to Alice\n",
        "dummy_model = AliceNet()\n",
        "plaintext_model = torch.load('tutorials/models/tutorial4_alice_model.pth')\n",
        "\n",
        "print(plaintext_model)\n",
        "\n",
        "# Encrypt the model from Alice:    \n",
        "\n",
        "# 1. Create a dummy input with the same shape as the model input\n",
        "dummy_input = torch.empty((1, 784))\n",
        "\n",
        "# 2. Construct a CrypTen network with the trained model and dummy_input\n",
        "private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
        "\n",
        "# 3. Encrypt the CrypTen network with src=ALICE\n",
        "private_model.encrypt(src=ALICE)\n",
        "\n",
        "#Check that model is encrypted:\n",
        "print(\"Model successfully encrypted:\", private_model.encrypted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AliceNet(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "Model successfully encrypted: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY3ZWMiIb5wh"
      },
      "source": [
        "## Classifying Encrypted Data with Encrypted Model\n",
        "\n",
        "We can now use Alice's encrypted network to classify Bob's data. For this, we need to encrypt Bob's data as well, as we did in Tutorial 3 (recall that Bob has the rank 1 process). Once Alice's network and Bob's data are both encrypted, CrypTen inference is performed with essentially identical steps as in PyTorch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBdZMpWkb5wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed64504c-a077-423c-ffff-54d0cf656a58"
      },
      "source": [
        "import crypten.mpc as mpc\n",
        "import crypten.communicator as comm\n",
        "\n",
        "labels = torch.load('/tmp/bob_test_labels.pth').long()\n",
        "count = 100 # For illustration purposes, we'll use only 100 samples for classification\n",
        "\n",
        "@mpc.run_multiprocess(world_size=2)\n",
        "def encrypt_model_and_data():\n",
        "    # Load pre-trained model to Alice\n",
        "    model = crypten.load_from_party('tutorials/models/tutorial4_alice_model.pth', src=ALICE)\n",
        "    \n",
        "    # Encrypt model from Alice \n",
        "    dummy_input = torch.empty((1, 784))\n",
        "    private_model = crypten.nn.from_pytorch(model, dummy_input)\n",
        "    private_model.encrypt(src=ALICE)\n",
        "    \n",
        "    # Load data to Bob\n",
        "    data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=BOB)\n",
        "    data_enc2 = data_enc[:count]\n",
        "    data_flatten = data_enc2.flatten(start_dim=1)\n",
        "\n",
        "    # Classify the encrypted data\n",
        "    private_model.eval()\n",
        "    output_enc = private_model(data_flatten)\n",
        "    \n",
        "    # Compute the accuracy\n",
        "    output = output_enc.get_plain_text()\n",
        "    accuracy = compute_accuracy(output, labels[:count])\n",
        "    crypten.print(\"\\tAccuracy: {0:.4f}\".format(accuracy.item()))\n",
        "    \n",
        "encrypt_model_and_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tAccuracy: 99.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbm9DbH-b5wl"
      },
      "source": [
        "## Validating Encrypted Classification\n",
        "\n",
        "Finally, we will verify that CrypTen classification results in encrypted output, and that this output can be decrypted into meaningful labels. \n",
        "\n",
        "To see this, in this tutorial, we will just check whether the result is an encrypted tensor; in the next tutorial, we will look into the values of tensor and confirm the encryption. We will also decrypt the result. As we discussed before, Alice and Bob both have access to the decrypted output of the model, and can both use this to obtain the labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4smPUx9b5wm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02caec7-8862-4632-b4c4-1b3941dffb7a"
      },
      "source": [
        "@mpc.run_multiprocess(world_size=2)\n",
        "def encrypt_model_and_data():\n",
        "    # Load pre-trained model to Alice\n",
        "    plaintext_model = crypten.load_from_party('tutorials/models/tutorial4_alice_model.pth', src=ALICE)\n",
        "    \n",
        "    # Encrypt model from Alice \n",
        "    dummy_input = torch.empty((1, 784))\n",
        "    private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
        "    private_model.encrypt(src=ALICE)\n",
        "    \n",
        "    # Load data to Bob\n",
        "    data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=BOB)\n",
        "    data_enc2 = data_enc[:count]\n",
        "    data_flatten = data_enc2.flatten(start_dim=1)\n",
        "\n",
        "    # Classify the encrypted data\n",
        "    private_model.eval()\n",
        "    output_enc = private_model(data_flatten)\n",
        "    \n",
        "    # Verify the results are encrypted: \n",
        "    crypten.print(\"Output tensor encrypted:\", crypten.is_encrypted_tensor(output_enc)) \n",
        "\n",
        "    # Decrypting the result\n",
        "    output = output_enc.get_plain_text()\n",
        "\n",
        "    # Obtaining the labels\n",
        "    pred = output.argmax(dim=1)\n",
        "    crypten.print(\"Decrypted labels:\\n\", pred)\n",
        "    \n",
        "encrypt_model_and_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output tensor encrypted: True\n",
            "Decrypted labels:\n",
            " tensor([7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
            "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
            "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0,\n",
            "        2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
            "        1, 7, 6, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "k8qWvwxEb5wx"
      },
      "source": [
        "This completes our tutorial. While we have used a simple network here to illustrate the concepts, CrypTen provides primitives to allow for encryption of substantially more complex networks. In our examples section, we demonstrate how CrypTen can be used to encrypt LeNet and ResNet, among others. \n",
        "\n",
        "Before exiting this tutorial, please clean up the files generated using the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Km0qHcHb5wy"
      },
      "source": [
        "import os\n",
        "\n",
        "filenames = ['/tmp/alice_train.pth', \n",
        "             '/tmp/alice_train_labels.pth', \n",
        "             '/tmp/bob_test.pth', \n",
        "             '/tmp/bob_test_labels.pth']\n",
        "\n",
        "for fn in filenames:\n",
        "    if os.path.exists(fn): os.remove(fn)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}